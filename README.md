# CEP_IITB_NRSC_2024
Basic coding for DeepLearning using Google colab
### Day 1 (04/03/24) : Coding (Basics of Pytorch, MLP)
In this coding tutorial, we delve into the fundamentals of PyTorch, a powerful open-source machine learning library, and explore the construction and training of Multi-Layer Perceptrons (MLPs). Multi-Layer Perceptrons are the building blocks of many deep learning models and serve as an excellent starting point for understanding neural networks.

Throughout the tutorial, we will cover essential concepts such as defining neural network architectures, implementing forward and backward propagation, optimizing model parameters using gradient descent, and evaluating model performance. We will leverage PyTorch's intuitive syntax and computational graph capabilities to create and train MLPs efficiently.

The tutorial will start with a brief overview of PyTorch, including tensor operations, automatic differentiation, and GPU acceleration, to provide a solid foundation for understanding the subsequent concepts. We will then proceed to implement a simple MLP architecture using PyTorch's nn.Module class, composing multiple fully connected layers with non-linear activation functions.

Moreover, we will discuss the importance of choosing appropriate activation functions, initializing model parameters effectively, and selecting loss functions and optimization algorithms suited for training MLPs. Practical examples and demonstrations will be provided to illustrate these concepts in action.

By the end of this tutorial, participants will gain a comprehensive understanding of PyTorch basics and be equipped with the knowledge and skills to construct, train, and evaluate MLP models for various machine learning tasks.
### Day 2 (05/03/24) : Coding (CNN for classification)
### Day 3 (06/03/24) : Coding (Autoencoder, RNN)
### Day 4 (07/03/24) : Coding (ViT, R-CNN/Yolo)
### Day 5 (08/03/24) : Coding (VAE, GAN)
