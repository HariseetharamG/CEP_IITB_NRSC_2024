# CEP_IITB_NRSC_2024
Basic coding for DeepLearning using Google colab
### Day 1 (04/03/24) : Coding (Basics of Pytorch, MLP)
In this coding tutorial, we delve into the fundamentals of PyTorch, a powerful open-source machine learning library, and explore the construction and training of Multi-Layer Perceptrons (MLPs). Multi-Layer Perceptrons are the building blocks of many deep learning models and serve as an excellent starting point for understanding neural networks.

Throughout the tutorial, we will cover essential concepts such as defining neural network architectures, implementing forward and backward propagation, optimizing model parameters using gradient descent, and evaluating model performance. We will leverage PyTorch's intuitive syntax and computational graph capabilities to create and train MLPs efficiently.

The tutorial will start with a brief overview of PyTorch, including tensor operations, automatic differentiation, and GPU acceleration, to provide a solid foundation for understanding the subsequent concepts. We will then proceed to implement a simple MLP architecture using PyTorch's nn.Module class, composing multiple fully connected layers with non-linear activation functions.

Moreover, we will discuss the importance of choosing appropriate activation functions, initializing model parameters effectively, and selecting loss functions and optimization algorithms suited for training MLPs. Practical examples and demonstrations will be provided to illustrate these concepts in action.

By the end of this tutorial, participants will gain a comprehensive understanding of PyTorch basics and be equipped with the knowledge and skills to construct, train, and evaluate MLP models for various machine learning tasks.
### Day 2 (05/03/24) : Coding (CNN for classification)
Convolutional Neural Networks (CNNs) are a class of deep neural networks specifically designed for tasks involving image recognition and classification. Comprising multiple layers, including convolutional, pooling, and fully connected layers, CNNs excel at automatically learning and extracting intricate patterns and features from input images. Their hierarchical architecture allows for effective feature representation, enabling the network to discern complex relationships within images and make accurate predictions. Through convolutional operations, CNNs capture local spatial dependencies, while pooling layers reduce dimensionality and retain important features. Fully connected layers at the end of the network aggregate extracted features to generate class predictions. CNNs have revolutionized computer vision tasks, achieving state-of-the-art performance in image classification, object detection, and semantic segmentation, making them a cornerstone of modern machine learning and artificial intelligence applications. In this tutorial, we will delve into the fundamentals of CNNs, exploring their architecture, training process, and applications, equipping you with the knowledge and skills to leverage CNNs effectively for image classification tasks.
### Day 3 (06/03/24) : Coding (Autoencoder, RNN)
### Day 4 (07/03/24) : Coding (ViT, R-CNN/Yolo)
### Day 5 (08/03/24) : Coding (VAE, GAN)
